{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","execution_count":6,"outputs":[{"output_type":"stream","text":"/kaggle/input/image-colorization/inception_resnet_v2_weights_tf_dim_ordering_tf_kernels.h5\n/kaggle/input/image-colorization/ab/ab/ab3.npy\n/kaggle/input/image-colorization/ab/ab/ab1.npy\n/kaggle/input/image-colorization/ab/ab/ab2.npy\n/kaggle/input/image-colorization/l/gray_scale.npy\n","name":"stdout"}]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"import tensorflow as tf\nfrom tensorflow.keras.layers import Conv2D,InputLayer, Conv2DTranspose, Dropout, BatchNormalization, Input, Concatenate, Activation, concatenate ,RepeatVector ,Reshape ,UpSampling2D\nfrom keras.initializers import RandomNormal\nfrom tensorflow.keras.models import Model, load_model, Sequential\nfrom tensorflow.keras.optimizers import Adam\nfrom skimage.transform import resize\nfrom sklearn.model_selection import train_test_split\nfrom tensorflow.keras.utils import plot_model\nimport numpy as np\nfrom tensorflow.keras.callbacks import EarlyStopping,ModelCheckpoint\nimport cv2\nimport PIL\nfrom skimage import transform\nfrom PIL import Image\nimport random\nimport h5py\nimport os\nimport plotly.graph_objects as go\nimport matplotlib.pyplot as plt\n","execution_count":7,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# ******> Loading the Data......**"},{"metadata":{"trusted":true},"cell_type":"code","source":"images_gray = np.load(\"../input/image-colorization/l/gray_scale.npy\")\nimages_ab1 = np.load(\"../input/image-colorization/ab/ab/ab1.npy\")\nimages_ab2 = np.load(\"../input/image-colorization/ab/ab/ab2.npy\")\nimages_ab3 = np.load(\"../input/image-colorization/ab/ab/ab3.npy\")\n","execution_count":8,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#taking training data of 100\nX_train = (images_gray[:100,:,:].astype('float')).reshape(100,224,224,1) #reshaping the input gray images\nY = (images_ab1[:100,:,:].astype('float'))\n","execution_count":9,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import tensorflow.compat.v1 as tf\ntf.disable_v2_behavior()\nfrom tensorflow.keras.applications.xception import Xception,decode_predictions,preprocess_input\nxception = Xception(weights='imagenet', include_top=True)\nxception.graph = tf.get_default_graph()","execution_count":11,"outputs":[{"output_type":"stream","text":"Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/xception/xception_weights_tf_dim_ordering_tf_kernels.h5\n91889664/91884032 [==============================] - 1s 0us/step\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"def create_Xception_embedding(grayscaled_rgb):\n    grayscaled_rgb_resized = []\n    for i in grayscaled_rgb:\n        i = resize(i, (299, 299, 3), mode='constant')\n        grayscaled_rgb_resized.append(i)\n    grayscaled_rgb_resized = np.array(grayscaled_rgb_resized)\n    grayscaled_rgb_resized = preprocess_input(grayscaled_rgb_resized)\n    with xception.graph.as_default():\n        embed = xception.predict(grayscaled_rgb_resized)\n    return embed","execution_count":12,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"xcept_em = create_Xception_embedding(X_train)\nembeddings = RepeatVector(28 * 28)(xcept_em)\nlayer_embeddings = Reshape(([28, 28, 1000]))(embeddings)","execution_count":14,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model_path = \"./color_model.h5\"\ncheckpoint = ModelCheckpoint(model_path,\n                            monitor = \"val_loss\",\n                            mode=\"min\",\n                            save_best_only = True,\n                            verbose = 1)\nes = EarlyStopping(monitor='val_loss', mode='min', verbose=1)","execution_count":15,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Encoder\nembed_input = Input(shape=(28, 28, 1000))\nencoder_input = Input(shape=(224, 224, 1,))\nencoder_1 = Conv2D(64, (3,3), activation='relu', padding='same', strides=2)(encoder_input)\nencoder_2 = Conv2D(128, (3,3), activation='relu', padding='same')(encoder_1)\nencoder_3 = Conv2D(128, (3,3), activation='relu', padding='same', strides=2)(encoder_2)\nencoder_4 = Conv2D(256, (3,3), activation='relu', padding='same')(encoder_3)\nencoder_5 = Conv2D(256, (3,3), activation='relu', padding='same', strides=2)(encoder_4)\nencoder_6 = Conv2D(512, (3,3), activation='relu', padding='same')(encoder_5)\nencoder_7 = Conv2D(512, (3,3), activation='relu', padding='same')(encoder_6)\nencoder_output= Conv2D(256, (3,3), activation='relu', padding='same')(encoder_7)\n#Fusion layer\nfusion_output = concatenate([encoder_output, layer_embeddings], axis=3) \nfusion_output = Conv2D(256, (1, 1), activation='relu', padding='same')(fusion_output)\nfusion_output = Conv2D(256, (1, 1), activation='relu', padding='same')(fusion_output)\n#Decoder layer\ndecoder_output = Conv2D(128, (3,3), activation='relu', padding='same')(fusion_output)\ndecoder_output = UpSampling2D((2, 2))(decoder_output)\ndecoder_output = Conv2D(64, (3,3), activation='relu', padding='same')(decoder_output)\ndecoder_output = UpSampling2D((2, 2))(decoder_output)\ndecoder_output = Conv2D(32, (3,3), activation='relu', padding='same')(decoder_output)\ndecoder_output = Conv2D(16, (3,3), activation='relu', padding='same')(decoder_output)\ndecoder_output = Conv2D(2, (3, 3), activation='relu', padding='same')(decoder_output)\ndecoder_output = UpSampling2D((2, 2))(decoder_output)\nmodel = Model(inputs=[encoder_input,embed_input], outputs=decoder_output)\nmodel.summary()","execution_count":16,"outputs":[{"output_type":"stream","text":"Model: \"functional_1\"\n__________________________________________________________________________________________________\nLayer (type)                    Output Shape         Param #     Connected to                     \n==================================================================================================\ninput_5 (InputLayer)            [(None, 224, 224, 1) 0                                            \n__________________________________________________________________________________________________\nconv2d_12 (Conv2D)              (None, 112, 112, 64) 640         input_5[0][0]                    \n__________________________________________________________________________________________________\nconv2d_13 (Conv2D)              (None, 112, 112, 128 73856       conv2d_12[0][0]                  \n__________________________________________________________________________________________________\nconv2d_14 (Conv2D)              (None, 56, 56, 128)  147584      conv2d_13[0][0]                  \n__________________________________________________________________________________________________\nconv2d_15 (Conv2D)              (None, 56, 56, 256)  295168      conv2d_14[0][0]                  \n__________________________________________________________________________________________________\nconv2d_16 (Conv2D)              (None, 28, 28, 256)  590080      conv2d_15[0][0]                  \n__________________________________________________________________________________________________\nconv2d_17 (Conv2D)              (None, 28, 28, 512)  1180160     conv2d_16[0][0]                  \n__________________________________________________________________________________________________\nconv2d_18 (Conv2D)              (None, 28, 28, 512)  2359808     conv2d_17[0][0]                  \n__________________________________________________________________________________________________\nconv2d_19 (Conv2D)              (None, 28, 28, 256)  1179904     conv2d_18[0][0]                  \n__________________________________________________________________________________________________\ntf_op_layer_reshape/Reshape (Te [(100, 28, 28, 1000) 0                                            \n__________________________________________________________________________________________________\nconcatenate (Concatenate)       (100, 28, 28, 1256)  0           conv2d_19[0][0]                  \n                                                                 tf_op_layer_reshape/Reshape[0][0]\n__________________________________________________________________________________________________\nconv2d_20 (Conv2D)              (100, 28, 28, 256)   321792      concatenate[0][0]                \n__________________________________________________________________________________________________\nconv2d_21 (Conv2D)              (100, 28, 28, 256)   65792       conv2d_20[0][0]                  \n__________________________________________________________________________________________________\nconv2d_22 (Conv2D)              (100, 28, 28, 128)   295040      conv2d_21[0][0]                  \n__________________________________________________________________________________________________\nup_sampling2d (UpSampling2D)    (100, 56, 56, 128)   0           conv2d_22[0][0]                  \n__________________________________________________________________________________________________\nconv2d_23 (Conv2D)              (100, 56, 56, 64)    73792       up_sampling2d[0][0]              \n__________________________________________________________________________________________________\nup_sampling2d_1 (UpSampling2D)  (100, 112, 112, 64)  0           conv2d_23[0][0]                  \n__________________________________________________________________________________________________\nconv2d_24 (Conv2D)              (100, 112, 112, 32)  18464       up_sampling2d_1[0][0]            \n__________________________________________________________________________________________________\nconv2d_25 (Conv2D)              (100, 112, 112, 16)  4624        conv2d_24[0][0]                  \n__________________________________________________________________________________________________\nconv2d_26 (Conv2D)              (100, 112, 112, 2)   290         conv2d_25[0][0]                  \n__________________________________________________________________________________________________\ninput_4 (InputLayer)            [(None, 28, 28, 1000 0                                            \n__________________________________________________________________________________________________\nup_sampling2d_2 (UpSampling2D)  (100, 224, 224, 2)   0           conv2d_26[0][0]                  \n==================================================================================================\nTotal params: 6,606,994\nTrainable params: 6,606,994\nNon-trainable params: 0\n__________________________________________________________________________________________________\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"model.compile(optimizer='adam', loss='mse',metrics=['accuracy'])\nhistory = model.fit(x=[X_train,layer_embeddings] ,y=Y,callbacks = [checkpoint,es], batch_size=5, epochs=1000,steps_per_epoch=1)","execution_count":null,"outputs":[{"output_type":"stream","text":"Train on 1 samples\nEpoch 1/1000\n1/1 [==============================] - 0s 2ms/step - batch: 0.0000e+00 - size: 1.0000 - loss: 18084.3008 - acc: 0.4482\nEpoch 2/1000\n1/1 [==============================] - 0s 2ms/step - batch: 0.0000e+00 - size: 1.0000 - loss: 20263.5039 - acc: 0.4483\nEpoch 3/1000\n1/1 [==============================] - 0s 2ms/step - batch: 0.0000e+00 - size: 1.0000 - loss: 17793.6621 - acc: 0.4483\nEpoch 4/1000\n1/1 [==============================] - 0s 2ms/step - batch: 0.0000e+00 - size: 1.0000 - loss: 18046.7070 - acc: 0.4483\nEpoch 5/1000\n1/1 [==============================] - 0s 2ms/step - batch: 0.0000e+00 - size: 1.0000 - loss: 18044.9395 - acc: 0.4476\nEpoch 6/1000\n1/1 [==============================] - 0s 2ms/step - batch: 0.0000e+00 - size: 1.0000 - loss: 17939.6055 - acc: 0.4476\nEpoch 7/1000\n1/1 [==============================] - 0s 2ms/step - batch: 0.0000e+00 - size: 1.0000 - loss: 17403.5156 - acc: 0.4477\nEpoch 8/1000\n1/1 [==============================] - 0s 2ms/step - batch: 0.0000e+00 - size: 1.0000 - loss: 14956.3232 - acc: 0.4474\nEpoch 9/1000\n1/1 [==============================] - 0s 2ms/step - batch: 0.0000e+00 - size: 1.0000 - loss: 6478.0483 - acc: 0.4474\nEpoch 10/1000\n1/1 [==============================] - 0s 2ms/step - batch: 0.0000e+00 - size: 1.0000 - loss: 105610.2422 - acc: 0.4478\nEpoch 11/1000\n1/1 [==============================] - 0s 2ms/step - batch: 0.0000e+00 - size: 1.0000 - loss: 5352.0229 - acc: 0.4504\nEpoch 12/1000\n1/1 [==============================] - 0s 3ms/step - batch: 0.0000e+00 - size: 1.0000 - loss: 13115.4375 - acc: 0.4503\nEpoch 13/1000\n1/1 [==============================] - 0s 2ms/step - batch: 0.0000e+00 - size: 1.0000 - loss: 16333.2910 - acc: 0.4486\nEpoch 14/1000\n1/1 [==============================] - 0s 2ms/step - batch: 0.0000e+00 - size: 1.0000 - loss: 17375.0098 - acc: 0.4471\nEpoch 15/1000\n1/1 [==============================] - 0s 2ms/step - batch: 0.0000e+00 - size: 1.0000 - loss: 17735.0176 - acc: 0.4483\nEpoch 16/1000\n1/1 [==============================] - 0s 2ms/step - batch: 0.0000e+00 - size: 1.0000 - loss: 17877.9746 - acc: 0.4501\nEpoch 17/1000\n1/1 [==============================] - 0s 2ms/step - batch: 0.0000e+00 - size: 1.0000 - loss: 17934.6660 - acc: 0.4494\nEpoch 18/1000\n1/1 [==============================] - 0s 3ms/step - batch: 0.0000e+00 - size: 1.0000 - loss: 17951.7344 - acc: 0.4505\nEpoch 19/1000\n1/1 [==============================] - 0s 7ms/step - batch: 0.0000e+00 - size: 1.0000 - loss: 17941.2266 - acc: 0.4517\nEpoch 20/1000\n1/1 [==============================] - 0s 4ms/step - batch: 0.0000e+00 - size: 1.0000 - loss: 17891.6211 - acc: 0.4517\nEpoch 21/1000\n1/1 [==============================] - 0s 2ms/step - batch: 0.0000e+00 - size: 1.0000 - loss: 17770.3809 - acc: 0.4508\nEpoch 22/1000\n1/1 [==============================] - 0s 3ms/step - batch: 0.0000e+00 - size: 1.0000 - loss: 17489.3496 - acc: 0.4502\nEpoch 23/1000\n1/1 [==============================] - 0s 2ms/step - batch: 0.0000e+00 - size: 1.0000 - loss: 16795.7852 - acc: 0.4497\nEpoch 24/1000\n1/1 [==============================] - 0s 2ms/step - batch: 0.0000e+00 - size: 1.0000 - loss: 15017.5850 - acc: 0.4500\nEpoch 25/1000\n1/1 [==============================] - 0s 2ms/step - batch: 0.0000e+00 - size: 1.0000 - loss: 10625.5674 - acc: 0.4494\nEpoch 26/1000\n1/1 [==============================] - 0s 2ms/step - batch: 0.0000e+00 - size: 1.0000 - loss: 4976.1440 - acc: 0.4474\nEpoch 27/1000\n1/1 [==============================] - 0s 2ms/step - batch: 0.0000e+00 - size: 1.0000 - loss: 27509.1523 - acc: 0.4471\nEpoch 28/1000\n1/1 [==============================] - 0s 4ms/step - batch: 0.0000e+00 - size: 1.0000 - loss: 5029.3696 - acc: 0.4511\nEpoch 29/1000\n1/1 [==============================] - 0s 2ms/step - batch: 0.0000e+00 - size: 1.0000 - loss: 9986.9453 - acc: 0.4540\nEpoch 30/1000\n1/1 [==============================] - 0s 2ms/step - batch: 0.0000e+00 - size: 1.0000 - loss: 13474.1914 - acc: 0.4557\nEpoch 31/1000\n1/1 [==============================] - 0s 2ms/step - batch: 0.0000e+00 - size: 1.0000 - loss: 15197.5381 - acc: 0.4658\nEpoch 32/1000\n1/1 [==============================] - 0s 2ms/step - batch: 0.0000e+00 - size: 1.0000 - loss: 16025.6719 - acc: 0.5004\nEpoch 33/1000\n1/1 [==============================] - 0s 2ms/step - batch: 0.0000e+00 - size: 1.0000 - loss: 16362.7949 - acc: 0.5286\nEpoch 34/1000\n1/1 [==============================] - 0s 2ms/step - batch: 0.0000e+00 - size: 1.0000 - loss: 16323.4873 - acc: 0.5402\nEpoch 35/1000\n1/1 [==============================] - 0s 4ms/step - batch: 0.0000e+00 - size: 1.0000 - loss: 15912.1416 - acc: 0.5422\nEpoch 36/1000\n1/1 [==============================] - 0s 4ms/step - batch: 0.0000e+00 - size: 1.0000 - loss: 14887.7061 - acc: 0.5407\nEpoch 37/1000\n1/1 [==============================] - 0s 2ms/step - batch: 0.0000e+00 - size: 1.0000 - loss: 12597.2217 - acc: 0.5323\nEpoch 38/1000\n1/1 [==============================] - 0s 2ms/step - batch: 0.0000e+00 - size: 1.0000 - loss: 7704.4194 - acc: 0.4812\nEpoch 39/1000\n1/1 [==============================] - 0s 2ms/step - batch: 0.0000e+00 - size: 1.0000 - loss: 6962.6606 - acc: 0.4537\nEpoch 40/1000\n1/1 [==============================] - 0s 3ms/step - batch: 0.0000e+00 - size: 1.0000 - loss: 5234.8286 - acc: 0.4571\nEpoch 41/1000\n1/1 [==============================] - 0s 3ms/step - batch: 0.0000e+00 - size: 1.0000 - loss: 4745.8945 - acc: 0.4774\nEpoch 42/1000\n1/1 [==============================] - 0s 2ms/step - batch: 0.0000e+00 - size: 1.0000 - loss: 5143.0635 - acc: 0.4758\nEpoch 43/1000\n1/1 [==============================] - 0s 4ms/step - batch: 0.0000e+00 - size: 1.0000 - loss: 4248.9790 - acc: 0.4691\nEpoch 44/1000\n1/1 [==============================] - 0s 15ms/step - batch: 0.0000e+00 - size: 1.0000 - loss: 6452.5654 - acc: 0.4634\nEpoch 45/1000\n1/1 [==============================] - 0s 6ms/step - batch: 0.0000e+00 - size: 1.0000 - loss: 4831.4883 - acc: 0.5422\nEpoch 46/1000\n1/1 [==============================] - 0s 4ms/step - batch: 0.0000e+00 - size: 1.0000 - loss: 6508.6504 - acc: 0.5477\nEpoch 47/1000\n1/1 [==============================] - 0s 2ms/step - batch: 0.0000e+00 - size: 1.0000 - loss: 5951.6660 - acc: 0.5475\nEpoch 48/1000\n1/1 [==============================] - 0s 2ms/step - batch: 0.0000e+00 - size: 1.0000 - loss: 4020.7544 - acc: 0.5433\nEpoch 49/1000\n1/1 [==============================] - 0s 2ms/step - batch: 0.0000e+00 - size: 1.0000 - loss: 6879.1943 - acc: 0.5272\nEpoch 50/1000\n1/1 [==============================] - 0s 6ms/step - batch: 0.0000e+00 - size: 1.0000 - loss: 3822.7788 - acc: 0.5428\nEpoch 51/1000\n1/1 [==============================] - 0s 5ms/step - batch: 0.0000e+00 - size: 1.0000 - loss: 4795.7495 - acc: 0.5474\nEpoch 52/1000\n1/1 [==============================] - 0s 2ms/step - batch: 0.0000e+00 - size: 1.0000 - loss: 5268.0063 - acc: 0.5479\nEpoch 53/1000\n1/1 [==============================] - 0s 3ms/step - batch: 0.0000e+00 - size: 1.0000 - loss: 4538.9790 - acc: 0.5473\nEpoch 54/1000\n1/1 [==============================] - 0s 4ms/step - batch: 0.0000e+00 - size: 1.0000 - loss: 3820.2000 - acc: 0.5457\nEpoch 55/1000\n1/1 [==============================] - 0s 2ms/step - batch: 0.0000e+00 - size: 1.0000 - loss: 4891.6494 - acc: 0.5428\nEpoch 56/1000\n1/1 [==============================] - 0s 2ms/step - batch: 0.0000e+00 - size: 1.0000 - loss: 3941.0310 - acc: 0.5437\nEpoch 57/1000\n1/1 [==============================] - 0s 2ms/step - batch: 0.0000e+00 - size: 1.0000 - loss: 3758.9321 - acc: 0.5450\nEpoch 58/1000\n1/1 [==============================] - 0s 11ms/step - batch: 0.0000e+00 - size: 1.0000 - loss: 4098.0620 - acc: 0.5455\nEpoch 59/1000\n1/1 [==============================] - 0s 3ms/step - batch: 0.0000e+00 - size: 1.0000 - loss: 3895.3291 - acc: 0.5456\nEpoch 60/1000\n1/1 [==============================] - 0s 6ms/step - batch: 0.0000e+00 - size: 1.0000 - loss: 3527.1387 - acc: 0.5447\nEpoch 61/1000\n1/1 [==============================] - 0s 4ms/step - batch: 0.0000e+00 - size: 1.0000 - loss: 4077.0735 - acc: 0.5423\nEpoch 62/1000\n","name":"stdout"},{"output_type":"stream","text":"1/1 [==============================] - 0s 5ms/step - batch: 0.0000e+00 - size: 1.0000 - loss: 3399.3770 - acc: 0.5432\nEpoch 63/1000\n1/1 [==============================] - 0s 5ms/step - batch: 0.0000e+00 - size: 1.0000 - loss: 3568.5889 - acc: 0.5445\nEpoch 64/1000\n1/1 [==============================] - 0s 2ms/step - batch: 0.0000e+00 - size: 1.0000 - loss: 3599.2473 - acc: 0.5454\nEpoch 65/1000\n1/1 [==============================] - 0s 2ms/step - batch: 0.0000e+00 - size: 1.0000 - loss: 3310.3616 - acc: 0.5454\nEpoch 66/1000\n1/1 [==============================] - 0s 2ms/step - batch: 0.0000e+00 - size: 1.0000 - loss: 3443.4282 - acc: 0.5456\nEpoch 67/1000\n1/1 [==============================] - 0s 2ms/step - batch: 0.0000e+00 - size: 1.0000 - loss: 3373.4387 - acc: 0.5469\nEpoch 68/1000\n1/1 [==============================] - 0s 2ms/step - batch: 0.0000e+00 - size: 1.0000 - loss: 3202.0242 - acc: 0.5493\nEpoch 69/1000\n1/1 [==============================] - 0s 2ms/step - batch: 0.0000e+00 - size: 1.0000 - loss: 3319.5425 - acc: 0.5499\nEpoch 70/1000\n1/1 [==============================] - 0s 2ms/step - batch: 0.0000e+00 - size: 1.0000 - loss: 3165.9160 - acc: 0.5495\nEpoch 71/1000\n1/1 [==============================] - 0s 2ms/step - batch: 0.0000e+00 - size: 1.0000 - loss: 3101.8833 - acc: 0.5496\nEpoch 72/1000\n1/1 [==============================] - 0s 2ms/step - batch: 0.0000e+00 - size: 1.0000 - loss: 3139.8188 - acc: 0.5498\nEpoch 73/1000\n1/1 [==============================] - 0s 4ms/step - batch: 0.0000e+00 - size: 1.0000 - loss: 2939.5156 - acc: 0.5501\nEpoch 74/1000\n1/1 [==============================] - 0s 2ms/step - batch: 0.0000e+00 - size: 1.0000 - loss: 2973.4209 - acc: 0.5507\nEpoch 75/1000\n1/1 [==============================] - 0s 4ms/step - batch: 0.0000e+00 - size: 1.0000 - loss: 2791.8914 - acc: 0.5509\nEpoch 76/1000\n1/1 [==============================] - 0s 2ms/step - batch: 0.0000e+00 - size: 1.0000 - loss: 3033.6021 - acc: 0.5514\nEpoch 77/1000\n1/1 [==============================] - 0s 2ms/step - batch: 0.0000e+00 - size: 1.0000 - loss: 2917.1714 - acc: 0.5505\nEpoch 78/1000\n1/1 [==============================] - 0s 2ms/step - batch: 0.0000e+00 - size: 1.0000 - loss: 2941.9495 - acc: 0.5507\nEpoch 79/1000\n1/1 [==============================] - 0s 2ms/step - batch: 0.0000e+00 - size: 1.0000 - loss: 2603.0054 - acc: 0.5510\nEpoch 80/1000\n1/1 [==============================] - 0s 2ms/step - batch: 0.0000e+00 - size: 1.0000 - loss: 3003.4070 - acc: 0.5509\nEpoch 81/1000\n1/1 [==============================] - 0s 2ms/step - batch: 0.0000e+00 - size: 1.0000 - loss: 2562.7561 - acc: 0.5508\nEpoch 82/1000\n1/1 [==============================] - 0s 4ms/step - batch: 0.0000e+00 - size: 1.0000 - loss: 2807.1697 - acc: 0.5511\nEpoch 83/1000\n1/1 [==============================] - 0s 2ms/step - batch: 0.0000e+00 - size: 1.0000 - loss: 2472.1665 - acc: 0.5511\nEpoch 84/1000\n1/1 [==============================] - 0s 7ms/step - batch: 0.0000e+00 - size: 1.0000 - loss: 2677.5442 - acc: 0.5503\nEpoch 85/1000\n1/1 [==============================] - 0s 2ms/step - batch: 0.0000e+00 - size: 1.0000 - loss: 2298.3748 - acc: 0.5507\nEpoch 86/1000\n1/1 [==============================] - 0s 2ms/step - batch: 0.0000e+00 - size: 1.0000 - loss: 2393.2166 - acc: 0.5512\nEpoch 87/1000\n1/1 [==============================] - 0s 2ms/step - batch: 0.0000e+00 - size: 1.0000 - loss: 2181.5579 - acc: 0.5509\nEpoch 88/1000\n1/1 [==============================] - 0s 2ms/step - batch: 0.0000e+00 - size: 1.0000 - loss: 2254.2058 - acc: 0.5500\nEpoch 89/1000\n1/1 [==============================] - 0s 2ms/step - batch: 0.0000e+00 - size: 1.0000 - loss: 1951.6893 - acc: 0.5496\nEpoch 90/1000\n1/1 [==============================] - 0s 2ms/step - batch: 0.0000e+00 - size: 1.0000 - loss: 1995.6747 - acc: 0.5493\nEpoch 91/1000\n1/1 [==============================] - 0s 2ms/step - batch: 0.0000e+00 - size: 1.0000 - loss: 1824.0824 - acc: 0.5492\nEpoch 92/1000\n1/1 [==============================] - 0s 2ms/step - batch: 0.0000e+00 - size: 1.0000 - loss: 1680.7354 - acc: 0.5491\nEpoch 93/1000\n1/1 [==============================] - 0s 2ms/step - batch: 0.0000e+00 - size: 1.0000 - loss: 1657.8682 - acc: 0.5485\nEpoch 94/1000\n1/1 [==============================] - 0s 2ms/step - batch: 0.0000e+00 - size: 1.0000 - loss: 1727.7802 - acc: 0.5477\nEpoch 95/1000\n1/1 [==============================] - 0s 3ms/step - batch: 0.0000e+00 - size: 1.0000 - loss: 1954.3588 - acc: 0.5475\nEpoch 96/1000\n1/1 [==============================] - 0s 2ms/step - batch: 0.0000e+00 - size: 1.0000 - loss: 1312.1949 - acc: 0.5472\nEpoch 97/1000\n1/1 [==============================] - 0s 2ms/step - batch: 0.0000e+00 - size: 1.0000 - loss: 2006.9484 - acc: 0.5458\nEpoch 98/1000\n1/1 [==============================] - 0s 2ms/step - batch: 0.0000e+00 - size: 1.0000 - loss: 2215.5217 - acc: 0.5487\nEpoch 99/1000\n1/1 [==============================] - 0s 2ms/step - batch: 0.0000e+00 - size: 1.0000 - loss: 2167.2920 - acc: 0.5491\nEpoch 100/1000\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.plot(history.history['loss'])\nplt.title('model loss')\nplt.ylabel('loss')\nplt.xlabel('epoch')\nplt.show()\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"output = model.predict([X_train,layer_embeddings],steps=3)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def get_LAB(image_l, image_ab  ):\n       \n    image_l = image_l.reshape((224, 224, 1))\n    image_lab = np.concatenate((image_l, image_ab), axis=2)\n    image_lab = image_lab.astype(\"uint8\")\n \n    image_rgb = cv2.cvtColor(image_lab, cv2.COLOR_LAB2RGB)\n    image_rgb = Image.fromarray(image_rgb)\n    return image_rgb\ndef get_LAB1(image_l  ):\n    image_ab =  np.ones((224,224,2))*128\n    image_l = image_l.reshape((224, 224, 1))\n    image_lab = np.concatenate((image_l, image_ab), axis=2)\n    image_lab = image_lab.astype(\"uint8\")\n \n    image_rgb = cv2.cvtColor(image_lab, cv2.COLOR_LAB2RGB)\n    image_rgb = Image.fromarray(image_rgb)\n    return image_rgb","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"for i in range(50):\n    pred = get_LAB(X_train[i],output[i])\n    real = get_LAB(X_train[i],Y[i])\n    original = get_LAB1(X_train[i])\n    f, axarr = plt.subplots(1,3)\n    axarr[0].title.set_text('Black and white')  \n    axarr[1].title.set_text('Prediction')  \n    axarr[2].title.set_text('original')  \n    axarr[0].imshow(original)\n    axarr[1].imshow(pred)\n    axarr[2].imshow(real)\n    ","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.7.6","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":4}