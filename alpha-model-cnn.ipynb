{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","execution_count":1,"outputs":[{"output_type":"stream","text":"/kaggle/input/image-colorization/inception_resnet_v2_weights_tf_dim_ordering_tf_kernels.h5\n/kaggle/input/image-colorization/ab/ab/ab3.npy\n/kaggle/input/image-colorization/ab/ab/ab1.npy\n/kaggle/input/image-colorization/ab/ab/ab2.npy\n/kaggle/input/image-colorization/l/gray_scale.npy\n","name":"stdout"}]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"import tensorflow as tf\nfrom tensorflow.keras.layers import Conv2D,InputLayer, Conv2DTranspose, Dropout, BatchNormalization, Input, Concatenate, Activation, concatenate ,RepeatVector ,Reshape ,UpSampling2D\nfrom keras.initializers import RandomNormal\nfrom tensorflow.keras.models import Model, load_model, Sequential\nfrom tensorflow.keras.optimizers import Adam\nfrom skimage.transform import resize\nfrom sklearn.model_selection import train_test_split\nfrom tensorflow.keras.utils import plot_model\nimport numpy as np\nfrom tensorflow.keras.callbacks import EarlyStopping,ModelCheckpoint\nimport cv2\nimport PIL\nfrom skimage import transform\nfrom PIL import Image\nimport random\nimport h5py\nimport os\nimport plotly.graph_objects as go\nimport matplotlib.pyplot as plt","execution_count":2,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"images_gray = np.load(\"../input/image-colorization/l/gray_scale.npy\")\nimages_ab1 = np.load(\"../input/image-colorization/ab/ab/ab1.npy\")\nimages_ab2 = np.load(\"../input/image-colorization/ab/ab/ab2.npy\")\nimages_ab3 = np.load(\"../input/image-colorization/ab/ab/ab3.npy\")\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#taking training data of 100\nX_train = (images_gray[:100,:,:].astype('float')).reshape(100,224,224,1) #reshaping the input gray images\nY = (images_ab1[:100,:,:].astype('float'))\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Model"},{"metadata":{"trusted":true},"cell_type":"code","source":"weight_init = RandomNormal(stddev=0.02)\nmodel = Sequential()\nmodel.add(InputLayer(input_shape=(224, 224, 1)))\nmodel.add(Conv2D(8, (3, 3), activation='relu', padding='same', strides=2,kernel_initializer=weight_init))\nmodel.add(Conv2D(8, (3, 3), activation='relu', padding='same',kernel_initializer=weight_init))\nmodel.add(Conv2D(16, (3, 3), activation='relu', padding='same',kernel_initializer=weight_init))\nmodel.add(Conv2D(16, (3, 3), activation='relu', padding='same', strides=2))\nmodel.add(Conv2D(32, (3, 3), activation='relu', padding='same',kernel_initializer=weight_init))\nmodel.add(Conv2D(32, (3, 3), activation='relu', padding='same', strides=2,kernel_initializer=weight_init))\nmodel.add(UpSampling2D((2, 2)))\nmodel.add(Conv2D(32, (3, 3), activation='relu', padding='same',kernel_initializer=weight_init))\nmodel.add(UpSampling2D((2, 2)))\nmodel.add(Conv2D(16, (3, 3), activation='relu', padding='same',kernel_initializer=weight_init))\nmodel.add(UpSampling2D((2, 2)))\nmodel.add(Conv2D(2, (3, 3), activation='relu', padding='same',kernel_initializer=weight_init))\nmodel.summary()\n\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Finish model\nmodel.compile(optimizer='rmsprop',loss='mse',metrics=['accuracy'])\n#Train the neural network\nhistory = model.fit(x=X_train, y=Y, batch_size=1, epochs=500)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.plot(history.history['loss'])\nplt.title('model loss')\nplt.ylabel('loss')\nplt.xlabel('epoch')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"output = model.predict(X_train)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"LAB TO RGB","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def get_LAB(image_l, image_ab  ):\n       \n    image_l = image_l.reshape((224, 224, 1))\n    image_lab = np.concatenate((image_l, image_ab), axis=2)\n    image_lab = image_lab.astype(\"uint8\")\n \n    image_rgb = cv2.cvtColor(image_lab, cv2.COLOR_LAB2RGB)\n    image_rgb = Image.fromarray(image_rgb)\n    return image_rgb\ndef get_LAB1(image_l  ):\n    image_ab =  np.ones((224,224,2))*128\n    image_l = image_l.reshape((224, 224, 1))\n    image_lab = np.concatenate((image_l, image_ab), axis=2)\n    image_lab = image_lab.astype(\"uint8\")\n \n    image_rgb = cv2.cvtColor(image_lab, cv2.COLOR_LAB2RGB)\n    image_rgb = Image.fromarray(image_rgb)\n    return image_rgb","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"Output","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"for i in range(50):\n    pred = get_LAB(X_train[i],output[i])\n    real = get_LAB(X_train[i],Y[i])\n    original = get_LAB1(X_train[i])\n    f, axarr = plt.subplots(1,3)\n    axarr[0].title.set_text('Black and white')  \n    axarr[1].title.set_text('Prediction')  \n    axarr[2].title.set_text('original')  \n    axarr[0].imshow(original)\n    axarr[1].imshow(pred)\n    axarr[2].imshow(real)\n    \n    \n    ","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.7.6","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":4}